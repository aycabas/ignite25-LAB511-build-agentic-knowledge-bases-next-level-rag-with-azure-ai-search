{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a0f14e9",
   "metadata": {},
   "source": [
    "# Azure AI Search Knowledge Bases with Blob Knowledge Source\n",
    "\n",
    "In Azure AI Search, a **knowledge base** is a top-level resource that connects a chat completion model to one or more **knowledge sources** (searchable indexes) for use in agentic retrieval workloads. It defines which data sources to query, which model to use for reasoning, and how query execution should be optimized, powering the `retrieve` method in an LLM-driven information retrieval pipeline. Once created, a knowledge base can be updated at any time, and changes will take effect the next time it’s used. \n",
    "\n",
    "This notebook demonstrates how to build **Knowledge Bases** with **knowledge sources**. You’ll learn how agentic retrieval works, how to create and configure a knowledge base, and how to query it for grounded, citation-backed answers while exploring the reasoning behind each step.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "In this lab, you will:\n",
    "* Connect to an existing blob knowledge source that contains indexed documents\n",
    "* Create a knowledge base that uses Azure OpenAI models for intelligent retrieval\n",
    "* Query the knowledge base with natural language to get grounded, citation-backed answers\n",
    "* Explore the agentic knowledge base's activity and reasoning process\n",
    "\n",
    "## Architecture Overview\n",
    "\n",
    "The lab environment has already provisioned:\n",
    "* **Azure Blob Storage** - Contains your source documents (PDFs about employee benefits)\n",
    "* **Azure AI Search** - Hosts the knowledge source with vectorized and indexed content\n",
    "* **Azure OpenAI** - Provides embedding and chat completion models\n",
    "\n",
    "The blob knowledge source uses **integrated vectorization** , a feature that automatically generates vector embeddings from your documents, builds a semantic search index, and connects the content to your knowledge base. This means you don’t need a separate preprocessing step before your data becomes searchable.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "The following **resources have already been prepared for you**:\n",
    "- ✅ Azure Blob Storage with uploaded documents\n",
    "- ✅ Azure AI Search service with knowledge source configured\n",
    "- ✅ Azure OpenAI with deployed models\n",
    "- ✅ Indexed documents ready for querying\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a923ac",
   "metadata": {},
   "source": [
    "## Step 1: Load Environment Variables\n",
    "\n",
    "> **‼️ Important:** Make sure to open the project on VSCode from  `ignite25-LAB511-build-knowledge-agents...` folder. Opening it from `LAB511` will cause dependency errors.\n",
    "\n",
    "Before we begin, we need to load the configuration for your Azure resources. The lab setup has created a `.env` file at the workspace root containing:\n",
    "\n",
    "* Azure AI Search endpoint and credentials  \n",
    "* Azure OpenAI endpoint, API key, and model deployment names  \n",
    "* Azure Blob Storage connection information  \n",
    "* Knowledge source and knowledge base names\n",
    "\n",
    "Run the cell below to load these environment variables into your Python session.\n",
    "\n",
    "> **📌 Tip** \n",
    "> - The first time you run the cell below, you'll be prompted to select Kernel, select **Install/Enable suggested extensions**, then select **Python Environments** and finally choose the **.venv(3.11.9)** environment that is created for you.\n",
    "> - You will also be prompted with \"Do you want to allow public and private networks to access this app?\" Select **Allow**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6498ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from azure.identity.aio import DefaultAzureCredential\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "import os\n",
    "\n",
    "load_dotenv(override=True) # take environment variables from .env.\n",
    "\n",
    "# Variables not used here do not need to be updated in your .env file\n",
    "endpoint = os.environ[\"AZURE_SEARCH_SERVICE_ENDPOINT\"]\n",
    "credential = AzureKeyCredential(os.getenv(\"AZURE_SEARCH_ADMIN_KEY\")) if os.getenv(\"AZURE_SEARCH_ADMIN_KEY\") else DefaultAzureCredential()\n",
    "knowledge_source_name = os.getenv(\"AZURE_SEARCH_KNOWLEDGE_SOURCE\", \"blob-knowledge-source\")\n",
    "knowledge_agent_name = os.getenv(\"AZURE_SEARCH_KNOWLEDGE_AGENT\", \"blob-knowledge-agent\")\n",
    "blob_connection_string = os.environ[\"BLOB_CONNECTION_STRING\"]\n",
    "# search blob datasource connection string is optional - defaults to blob connection string\n",
    "# This field is only necessary if you are using MI to connect to the data source\n",
    "# https://learn.microsoft.com/azure/search/search-howto-indexing-azure-blob-storage#supported-credentials-and-connection-strings\n",
    "search_blob_connection_string = os.getenv(\"SEARCH_BLOB_DATASOURCE_CONNECTION_STRING\", blob_connection_string)\n",
    "blob_container_name = os.getenv(\"BLOB_CONTAINER_NAME\", \"documents\")\n",
    "azure_openai_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "azure_openai_key = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "azure_openai_embedding_deployment = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\", \"text-embedding-3-large\")\n",
    "azure_openai_embedding_model_name = os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL_NAME\", \"text-embedding-3-large\")\n",
    "azure_openai_chatgpt_deployment = os.getenv(\"AZURE_OPENAI_CHATGPT_DEPLOYMENT\", \"gpt-5\")\n",
    "azure_openai_chatgpt_model_name = os.getenv(\"AZURE_OPENAI_CHATGPT_MODEL_NAME\", \"gpt-5\")\n",
    "use_verbalization = os.getenv(\"USE_VERBALIZATION\", \"false\") == \"true\"\n",
    "\n",
    "# Add a message to indicate that the environment variables have been loaded\n",
    "print(\"Environment variables loaded. You can now create the knowledge base.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bb33a4",
   "metadata": {},
   "source": [
    "## Step 2: Create a blob knowledge source on Azure AI Search\n",
    "\n",
    "A **Knowledge Source** in Azure AI Search is a searchable index enriched with metadata and vectorized content that the agentic knowledge base can use to retrieve information.Creating a blob knowledge source sets up all necessary resources to index the uploaded document.\n",
    "\n",
    "Run the cell below to create a blob knowledge source in your Azure AI Search service. This process may take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa342b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes.models import (\n",
    "    AzureSearchIndexKnowledgeSource,\n",
    "    KnowledgeAgentAzureOpenAIModel,\n",
    "    AzureOpenAIVectorizerParameters\n",
    ")\n",
    "from azure.search.documents.indexes.aio import SearchIndexClient\n",
    "\n",
    "chat_model = KnowledgeAgentAzureOpenAIModel(\n",
    "    azure_open_ai_parameters=AzureOpenAIVectorizerParameters(\n",
    "        resource_url=azure_openai_endpoint,\n",
    "        deployment_name=azure_openai_chatgpt_deployment,\n",
    "        api_key=azure_openai_key,\n",
    "        model_name=azure_openai_chatgpt_model_name\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create knowledge source for hrdocs index\n",
    "hrdocs_knowledge_source = AzureSearchIndexKnowledgeSource(\n",
    "    name=\"hrdocs-knowledge-source\",\n",
    "    index_name=\"hrdocs\"\n",
    ")\n",
    "\n",
    "# Create knowledge source for healthdocs index\n",
    "healthdocs_knowledge_source = AzureSearchIndexKnowledgeSource(\n",
    "    name=\"healthdocs-knowledge-source\",\n",
    "    index_name=\"healthdocs\"\n",
    ")\n",
    "\n",
    "async with SearchIndexClient(endpoint=endpoint, credential=credential) as client:\n",
    "    await client.create_or_update_knowledge_source(hrdocs_knowledge_source)\n",
    "    print(f\"Created knowledge source: {hrdocs_knowledge_source.name}\")\n",
    "    \n",
    "    await client.create_or_update_knowledge_source(healthdocs_knowledge_source)\n",
    "    print(f\"Created knowledge source: {healthdocs_knowledge_source.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cdb045",
   "metadata": {},
   "source": [
    "## Step 3: Create a Knowledge Base\n",
    "\n",
    "A **Knowledge Base** is an intelligent layer that connects your indexed data to a language model. Instead of just returning search results, it plans queries, retrieves relevant data, and generates grounded answers.\n",
    "\n",
    "In this step, we'll create a knowledge base that acts as an intelligent wrapper around your knowledge source and LLM deployment.\n",
    "\n",
    "### Output Modality Options\n",
    "\n",
    "The knowledge base supports two output modalities:\n",
    "* **`EXTRACTIVE_DATA`** (default) - Returns exact content from your knowledge sources without generative alteration\n",
    "* **`ANSWER_SYNTHESIS`** (used here) - Generates natural language answers using the LLM that cite the retrieved content\n",
    "\n",
    "We're using `ANSWER_SYNTHESIS` with `include_activity=True` to get:\n",
    "* **LLM-generated answers** that cite retrieved documents\n",
    "* **Detailed activity logs** showing the knowledge base's reasoning process, including subqueries and re-ranking decisions\n",
    "\n",
    "Learn more about [answer synthesis in Azure AI Search](https://learn.microsoft.com/azure/search/search-agentic-retrieval-how-to-synthesize).\n",
    "\n",
    "Run the cell below to create the knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f5a2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes.models import KnowledgeAgent, KnowledgeSourceReference, KnowledgeAgentOutputConfiguration, KnowledgeAgentOutputConfigurationModality\n",
    "\n",
    "output_config = KnowledgeAgentOutputConfiguration(\n",
    "    modality=KnowledgeAgentOutputConfigurationModality.ANSWER_SYNTHESIS,\n",
    "    include_activity=True\n",
    ")\n",
    "\n",
    "agent = KnowledgeAgent(\n",
    "    name=knowledge_agent_name,\n",
    "    models=[chat_model],\n",
    "    knowledge_sources=[\n",
    "        KnowledgeSourceReference(\n",
    "            name=hrdocs_knowledge_source.name,\n",
    "            include_reference_source_data=True,\n",
    "            always_query_source=True\n",
    "        ),\n",
    "        KnowledgeSourceReference(\n",
    "            name=healthdocs_knowledge_source.name,\n",
    "            include_reference_source_data=True,\n",
    "            always_query_source=True\n",
    "        )\n",
    "    ],\n",
    "    output_configuration=output_config\n",
    ")\n",
    "\n",
    "async with SearchIndexClient(endpoint=endpoint, credential=credential) as index_client:\n",
    "    await index_client.create_or_update_agent(agent)\n",
    "    print(f\"Created knowledge agent: {agent.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78ca732",
   "metadata": {},
   "source": [
    "## Step 4: Query the Knowledge Base\n",
    "\n",
    "Now it’s time to query our documents and see agentic retrieval in action. This step demonstrates how the knowledge base processes queries to produce grounded, citation-backed answers.\n",
    "\n",
    "### How Agentic Retrieval Works\n",
    "\n",
    "Given a user query and conversation history, the knowledge base:\n",
    "1. **Analyzes the conversation** - Understands the full context and user's information need\n",
    "2. **Query decomposition** - Breaks down complex queries into focused subqueries\n",
    "3. **Concurrent execution** - Runs subqueries in parallel against your knowledge source\n",
    "4. **Semantic reranking** - Uses semantic ranker to rerank and filter results for relevance\n",
    "5. **Answer synthesis** - Synthesizes the top results into a natural-language answer with citations\n",
    "\n",
    "### Example Query\n",
    "\n",
    "The example below asks about differences between two employee benefit plans. The agentic knowledge base will:\n",
    "* Search across the indexed PDF documents\n",
    "* Find relevant sections from both plans\n",
    "* Generate a comparative answer with specific citations\n",
    "\n",
    "Try running the cell below, then modify the `text` field in the `messages` list to ask your own questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda61b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.agent.aio import KnowledgeAgentRetrievalClient\n",
    "from azure.search.documents.agent.models import KnowledgeAgentRetrievalRequest, KnowledgeAgentMessage, KnowledgeAgentMessageTextContent\n",
    "import warnings\n",
    "\n",
    "# Suppress aiohttp warnings\n",
    "warnings.filterwarnings('ignore', category=ResourceWarning)\n",
    "\n",
    "messages = [\n",
    "    KnowledgeAgentMessage(\n",
    "        role=\"user\",\n",
    "        content=[KnowledgeAgentMessageTextContent(\n",
    "            text=\"Differences between Northwind Health Plus and Standard\"\n",
    "        )]\n",
    "    )\n",
    "]\n",
    "\n",
    "agent_client = KnowledgeAgentRetrievalClient(endpoint=endpoint, agent_name=knowledge_agent_name, credential=credential)\n",
    "try:\n",
    "    print(\"🔍 Querying the knowledge base...\")\n",
    "    result = await agent_client.retrieve(KnowledgeAgentRetrievalRequest(messages=messages))\n",
    "    print(\"✅ Query successful! The agentic knowledge base has retrieved relevant information.\")\n",
    "    print(\"📊 Run the cells in Step 5 below to review the response, activity, and references.\")\n",
    "finally:\n",
    "    await agent_client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3e3e31",
   "metadata": {},
   "source": [
    "## Step 5: Review the Retrieval Response\n",
    "\n",
    "The knowledge base's response contains three key components that provide full transparency into the retrieval process:\n",
    "\n",
    "### 1. Response Content (Answer)\n",
    "An LLM-generated answer to your query that cites the retrieved documents. This is the primary output you'd show to end users.\n",
    "\n",
    "### 2. Activity Content (Reasoning)\n",
    "Detailed planning and execution information showing:\n",
    "* **Subqueries generated** - How the agentic knowledge base broke down your query\n",
    "* **Reranking decisions** - Which results were promoted or filtered\n",
    "* **Intermediate steps** - The agentic knowledge base's thought process and execution flow\n",
    "\n",
    "### 3. References Content (Sources)\n",
    "Source documents and text chunks that contributed to the answer, including:\n",
    "* Document names and metadata\n",
    "* Specific text passages used\n",
    "* Relevance scores and rankings\n",
    "\n",
    "### Why This Matters\n",
    "\n",
    "These three components enable you to:\n",
    "* **Verify grounding** - Ensure answers are based on your actual content\n",
    "* **Build traceable citations** - Create links back to source documents\n",
    "* **Debug and optimize** - Understand why certain results were retrieved\n",
    "* **Tune retrieval parameters** - Adjust reranker thresholds and knowledge source settings\n",
    "\n",
    "> **💡 Tip:** Retrieval parameters (like reranker thresholds and knowledge source parameters) influence how aggressively your agentic knowledge base reranks results and which sources it queries. Inspect the activity and references to validate grounding quality.\n",
    "\n",
    "Let's examine each component! \n",
    "\n",
    "Run the first cell below to display the **synthesized answer** with citations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94562da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Agentic knowledge base's Response (synthesized answer):\")\n",
    "print(result.response[0].content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0cda0d",
   "metadata": {},
   "source": [
    "Run the cell below to display the **agentic knowledge base's activity log** showing query decomposition and reasoning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b53cc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Activity -> JSON string of activity as list of dicts\n",
    "\n",
    "activity_content = json.dumps([a.as_dict() for a in result.activity], indent=2)\n",
    "print(\"activity_content:\\n\", activity_content, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81efa74",
   "metadata": {},
   "source": [
    "Run the cell below to display the **source references** used to generate the answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f64b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# References -> JSON string of references as list of dicts\n",
    "references_content = json.dumps([r.as_dict() for r in result.references], indent=2)\n",
    "print(\"references_content:\\n\", references_content, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8d8b00",
   "metadata": {},
   "source": [
    "## Notebook Complete! 🎉\n",
    "\n",
    "Congratulations! You've successfully completed the hands-on portion of this lab.\n",
    "\n",
    "### What You Learned: The Agentic Knowledge Base Orchestration Layer\n",
    "\n",
    "This lab focused on the **intelligence layer** that sits on top of search infrastructure. Here's the real depth of what you explored:\n",
    "\n",
    "#### **1. Knowledge Bases as Orchestrators**\n",
    "You built a knowledge base that doesn't just search—it **orchestrates** an entire retrieval workflow. The knowledge base coordinates between your knowledge sources (the indexed blob data) and the LLM (GPT model) to produce grounded, citation-backed answers.\n",
    "\n",
    "#### **2. Answer Synthesis vs. Raw Retrieval**\n",
    "Traditional search returns chunks of text. You configured **Answer Synthesis mode**, where the LLM reads retrieved passages and generates a coherent natural-language response with inline citations. This is the foundation of modern copilots and chat interfaces over enterprise data.\n",
    "\n",
    "#### **3. Query Decomposition & Planning**\n",
    "When you examined the **activity logs**, you saw how the knowledge base breaks complex queries into focused subqueries, executes them in parallel, and applies semantic reranking. This is agentic behavior—the system plans and adapts based on the query context.\n",
    "\n",
    "#### **4. Grounding & Transparency**\n",
    "Every answer is backed by source references. You explored how to trace responses back to specific documents and passages, enabling trust and auditability in AI systems. The activity logs show exactly how the knowledge base arrived at its answer.\n",
    "\n",
    "#### **5. The RAG Evolution**\n",
    "This lab demonstrated **Retrieval-Augmented Generation (RAG)** at scale. The knowledge base doesn't just retrieve—it reasons about what to retrieve, how to combine results, and how to synthesize coherent answers. This is next-level RAG: agentic, explainable, and production-ready.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "📖 **Return to the lab instructions page** to have a look at the summary and reflect on how **agentic behavior elevates RAG beyond simple search**, explore additional learning resources, and understand how to apply these patterns to real-world enterprise AI solutions.\n",
    "\n",
    "💡 **Experiment more!** Go back to Step 4 and try different queries—watch how the agentic knowledge base adapts its retrieval strategy based on query complexity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "knowledge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
